{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "metric-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import echonet\n",
    "from echonet.datasets import Echo\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models.video import r2plus1d_18\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "from src.utils.torch_utils import TransformDataset, torch_collate\n",
    "from src.utils.echo_utils import get2dPucks\n",
    "from src.utils.camus_validate import cleanupSegmentation\n",
    "from src.transform_utils import generate_2dmotion_field\n",
    "from src.visualization_utils import categorical_dice\n",
    "from src.loss_functions import huber_loss, convert_to_1hot, convert_to_1hot_tensor\n",
    "from src.model.R2plus1D_18_MotionNet import R2plus1D_18_MotionNet\n",
    "from src.echonet_dataset import EchoNetDynamicDataset, EDESpairs\n",
    "# from src.visualization_utils import categorical_dice\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "tic, toc = (time.time, time.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "affiliated-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_workers = max(4, cpu_count()//2)\n",
    "\n",
    "\n",
    "def worker_init_fn_valid(worker_id):                                                          \n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
    "    \n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    # See here: https://pytorch.org/docs/stable/notes/randomness.html#dataloader\n",
    "    # and the original post of the problem: https://github.com/pytorch/pytorch/issues/5059#issuecomment-817373837\n",
    "    worker_seed = torch.initial_seed() % 2 ** 32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "    \n",
    "\n",
    "def permuter(list1, list2):\n",
    "    for i1 in list1:\n",
    "        for i2 in list2:\n",
    "            yield (i1, i2)\n",
    "            \n",
    "\n",
    "param_trainLoader = {'collate_fn': torch_collate,\n",
    "                     'batch_size': batch_size,\n",
    "                     'num_workers': max(4, cpu_count()//2),\n",
    "                     'worker_init_fn': worker_init_fn}\n",
    "\n",
    "param_testLoader = {'collate_fn': torch_collate,\n",
    "                    'batch_size': batch_size,\n",
    "                    'shuffle': False,\n",
    "                    'num_workers': max(4, cpu_count()//2),\n",
    "                    'worker_init_fn': worker_init_fn}\n",
    "\n",
    "paramLoader = {'train': param_trainLoader,\n",
    "               'valid': param_testLoader,\n",
    "               'test':  param_testLoader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "athletic-spending",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00, 14.63it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 13.68it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"fold_indexes/stanford_valid_sampled_indices\", \"rb\") as infile:\n",
    "    valid_mask = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "full_dataset = EchoNetDynamicDataset(split='val', clip_length=\"full\", subset_indices=valid_mask, period=1)\n",
    "test_dataset = EchoNetDynamicDataset(split='test', clip_length=\"full\", raise_for_es_ed=False, period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "governing-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_to_consecutive_clips(video, clip_length=32, interpolate_last=False):\n",
    "    source_video = video.copy()\n",
    "    video_length = video.shape[1]\n",
    "    left = video_length % clip_length\n",
    "    if left != 0 and interpolate_last:\n",
    "        source_video = torch.Tensor(source_video).unsqueeze(0)\n",
    "        source_video = F.interpolate(source_video, size=(int(np.round(video_length / clip_length) * clip_length), 112, 112),\n",
    "                                     mode=\"trilinear\", align_corners=False)\n",
    "        source_video = source_video.squeeze(0).squeeze(0)\n",
    "        source_video = source_video.numpy()\n",
    "    \n",
    "    videos = np.empty(shape=(1, 3, clip_length, 112, 112))\n",
    "\n",
    "    for start in range(0, int(clip_length * np.round(video_length / clip_length)), clip_length):\n",
    "        one_clip = source_video[:, start: start + clip_length]\n",
    "        one_clip = np.expand_dims(one_clip, 0)\n",
    "        videos = np.concatenate([videos, one_clip])\n",
    "    return videos[1:]\n",
    "\n",
    "\n",
    "def get_all_possible_start_points(ed_index, es_index, video_length, clip_length):\n",
    "    assert es_index - ed_index > 0, \"not a ED to ES clip pair\"\n",
    "    possible_shift = clip_length - (es_index - ed_index)\n",
    "    allowed_right = video_length - es_index\n",
    "    if allowed_right < possible_shift:\n",
    "        return np.arange(ed_index - possible_shift + 1, video_length - clip_length + 1)\n",
    "    if possible_shift < 0:\n",
    "        return np.array([ed_index])\n",
    "    elif ed_index < possible_shift:\n",
    "        return np.arange(ed_index)\n",
    "    else:\n",
    "        return np.arange(ed_index - possible_shift + 1, ed_index + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "manufactured-arizona",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2+1D MotionNet has 31575731 parameters.\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"save_models/R2plus1DMotionSegNet_model_tmp.pth\"\n",
    "\n",
    "model = torch.nn.DataParallel(R2plus1D_18_MotionNet())\n",
    "model.to(\"cuda\")\n",
    "torch.cuda.empty_cache()\n",
    "model.load_state_dict(torch.load(model_save_path)[\"model\"])\n",
    "print(f'R2+1D MotionNet has {sum(p.numel() for p in model.parameters() if p.requires_grad)} parameters.')\n",
    "\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-photographer",
   "metadata": {},
   "source": [
    "### Compute EF for all test patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "elementary-cloud",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dynamic37-labelfusion/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/opt/anaconda3/envs/dynamic37-labelfusion/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot identify clips at patient:0095\n",
      "Cannot identify clips at patient:0156\n",
      "Cannot identify clips at patient:0294\n",
      "Cannot identify clips at patient:0390\n",
      "Cannot identify clips at patient:0573\n",
      "Cannot identify clips at patient:0612\n",
      "Cannot identify clips at patient:0761\n",
      "Cannot identify clips at patient:0832\n",
      "Cannot identify clips at patient:1061\n"
     ]
    }
   ],
   "source": [
    "EF_list = []\n",
    "true_EF_list = []\n",
    "mean_EF_list = []\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    test_pat_index = i\n",
    "    try:\n",
    "        video, (filename, EF, es_clip_index, ed_clip_index, es_index, ed_index, es_frame, ed_frame, es_label, ed_label) = test_dataset[test_pat_index]\n",
    "    except:\n",
    "        print(\"Get exception when trying to read the video from patient:{:04d}\".format(i))\n",
    "        continue\n",
    "    interpolate_last = True\n",
    "\n",
    "    consecutive_clips = divide_to_consecutive_clips(video, interpolate_last=interpolate_last)\n",
    "\n",
    "    segmentation_outputs = np.empty(shape=(1, 2, 32, 112, 112))\n",
    "    motion_outputs = np.empty(shape=(1, 4, 32, 112, 112))\n",
    "\n",
    "    for i in range(consecutive_clips.shape[0]):\n",
    "        one_clip = np.expand_dims(consecutive_clips[i], 0)\n",
    "        segmentation_output, motion_output = model(torch.Tensor(one_clip))\n",
    "        segmentation_output = F.softmax(segmentation_output, 1)\n",
    "        segmentation_outputs = np.concatenate([segmentation_outputs, segmentation_output.cpu().detach().numpy()])\n",
    "        motion_outputs = np.concatenate([motion_outputs, motion_output.cpu().detach().numpy()])\n",
    "    segmentation_outputs = segmentation_outputs[1:]\n",
    "    motion_outputs = motion_outputs[1:]\n",
    "   \n",
    "    # --- Modification Begin ---\n",
    "    segmentation_outputs = segmentation_outputs.transpose([1, 0, 2, 3, 4])\n",
    "    segmentation_outputs = segmentation_outputs.reshape(2, -1, 112, 112)\n",
    "    if interpolate_last and (video.shape[1] % 32 != 0):\n",
    "        interpolated_segmentations = torch.Tensor(segmentation_outputs).unsqueeze(0)\n",
    "        interpolated_segmentations = F.interpolate(interpolated_segmentations, size=(video.shape[1], 112, 112), \n",
    "                                                   mode=\"trilinear\", align_corners=False)\n",
    "        interpolated_segmentations = interpolated_segmentations.squeeze(0).numpy()\n",
    "        segmentation_outputs = np.argmax(interpolated_segmentations, 0)\n",
    "\n",
    "        segmentations = segmentation_outputs\n",
    "    else:\n",
    "        segmentations = np.argmax(segmentation_outputs, axis=0)\n",
    "    # --- Modification End ---\n",
    "    \n",
    "\n",
    "    size = np.sum(segmentations, axis=(1, 2)).ravel()\n",
    "    _05cut, _85cut, _95cut = np.percentile(size, [5, 85, 95]) \n",
    "\n",
    "    trim_min = _05cut\n",
    "    trim_max = _95cut\n",
    "    trim_range = trim_max - trim_min\n",
    "    systole = find_peaks(-size, distance=20, prominence=(0.50 * trim_range))[0]\n",
    "    diastole = find_peaks(size, distance=20, prominence=(0.50 * trim_range))[0]\n",
    "\n",
    "    # keep only real diastoles..\n",
    "    diastole = [x for x in diastole if size[x] >= _85cut]\n",
    "    # Add first frame\n",
    "    if np.mean(size[:3]) >= _85cut:\n",
    "        diastole = [0] + diastole\n",
    "    diastole = np.array(diastole)\n",
    "\n",
    "    clip_pairs = EDESpairs(diastole, systole)\n",
    "\n",
    "    one_array_of_segmentations = segmentations\n",
    "\n",
    "    predicted_efs = []\n",
    "\n",
    "    for i in range(len(clip_pairs)):\n",
    "        output_ED = one_array_of_segmentations[clip_pairs[i][0]]\n",
    "        output_ES = one_array_of_segmentations[clip_pairs[i][1]]\n",
    "\n",
    "        length_ed, radius_ed = get2dPucks(((output_ED) == 1).astype('int'), (1.0, 1.0))\n",
    "        length_es, radius_es = get2dPucks(((output_ES) == 1).astype('int'), (1.0, 1.0))\n",
    "\n",
    "        edv = np.sum(((np.pi * radius_ed * radius_ed) * length_ed / len(radius_ed)))\n",
    "        esv = np.sum(((np.pi * radius_es * radius_es) * length_es / len(radius_es)))\n",
    "\n",
    "        ef_predicted = (edv - esv) / edv * 100\n",
    "\n",
    "        predicted_efs.append(ef_predicted)\n",
    "    \n",
    "    if np.isnan(np.mean(predicted_efs)):\n",
    "        if len(predicted_efs) == 0:\n",
    "            print(\"Cannot identify clips at patient:{:04d}\".format(test_pat_index))\n",
    "            continue\n",
    "        else:\n",
    "            print(\"Nan EF at patient:{:04d}\".format(test_pat_index))\n",
    "    \n",
    "    EF_list.append(predicted_efs)\n",
    "    true_EF_list.append(EF)\n",
    "    mean_EF_list.append(np.nanmean(predicted_efs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-property",
   "metadata": {},
   "source": [
    "### Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cognitive-relay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error (standard deviation):  5.3737 (4.9693) %\n",
      "Median absolute error:  4.2037 %\n",
      "Bias +- 1.96 x std:  -2.2112 +- 13.6753\n",
      "Percentile of mae 50%: 4.2037  75%: 7.4805  95%: 14.1865\n"
     ]
    }
   ],
   "source": [
    "errors = np.array(np.array(true_EF_list) - np.array(mean_EF_list))\n",
    "abs_errors = abs(errors)\n",
    "\n",
    "print(\"Mean absolute error (standard deviation):  {:.4f} ({:.4f}) %\".format(np.mean(abs_errors), np.std(abs_errors)))\n",
    "print(\"Median absolute error:  {:.4f} %\".format(np.median(abs_errors)))\n",
    "print(\"Bias +- 1.96 x std:  {:.4f} +- {:.4f}\".format(np.mean(errors), 1.96 * np.std(errors)))\n",
    "print(\"Percentile of mae 50%: {:6.4f}  75%: {:6.4f}  95%: {:6.4f}\".format(np.percentile(abs_errors, 50), np.percentile(abs_errors, 75),\n",
    "                                                                    np.percentile(abs_errors, 95)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-capitol",
   "metadata": {},
   "source": [
    "### Cross Correlation with True EF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "democratic-wheat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross correlation with True EF: 0.833\n"
     ]
    }
   ],
   "source": [
    "drop_ind_arr = ~np.isnan(mean_EF_list)\n",
    "corrcoef = np.corrcoef(np.array(true_EF_list)[drop_ind_arr], np.array(mean_EF_list)[drop_ind_arr])\n",
    "print(\"Cross correlation with True EF: {:.3f}\".format(corrcoef[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-juvenile",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "organic-contents",
   "metadata": {},
   "source": [
    "### Check with Ground True Labels\n",
    "Estimate the ejection fraction using the provided manual $LV_{endo}$ annotation. The approximation protocol is still the Simpson's monoplane method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "capital-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "derived_reported_EF_list = []\n",
    "true_EF_list = []\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    test_pat_index = i\n",
    "    try:\n",
    "        video, (filename, EF, es_clip_index, ed_clip_index, es_index, ed_index, es_frame, ed_frame, es_label, ed_label) = test_dataset[test_pat_index]\n",
    "    except:\n",
    "        print(\"Get exception when trying to read the video from patient:{:04d}\".format(i))\n",
    "        continue\n",
    "    \n",
    "    output_ED = ed_label\n",
    "    output_ES = es_label\n",
    "\n",
    "    length_ed, radius_ed = get2dPucks((output_ED == 1).astype('int'), (1.0, 1.0))\n",
    "    length_es, radius_es = get2dPucks((output_ES == 1).astype('int'), (1.0, 1.0))\n",
    "\n",
    "    edv = np.sum(((np.pi * radius_ed * radius_ed) * length_ed / len(radius_ed)))\n",
    "    esv = np.sum(((np.pi * radius_es * radius_es) * length_es / len(radius_es)))\n",
    "\n",
    "    ef_predicted = (edv - esv) / edv * 100\n",
    "    \n",
    "    if np.isnan(ef_predicted):\n",
    "        print(\"Nan EF at patient:{:04d}\".format(test_pat_index))\n",
    "    \n",
    "    derived_reported_EF_list.append(ef_predicted)\n",
    "    true_EF_list.append(EF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-reynolds",
   "metadata": {},
   "source": [
    "### Mean Absolute Error between the Reported EF and EF computed from Reported ED/ES labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "posted-minnesota",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error (standard deviation):  1.5450 (2.1868) %\n",
      "Median absolute error:  1.0394 %\n",
      "Bias +- 1.96 x std:  -0.5295 +- 5.1443\n",
      "Percentile of mae 50%: 1.0394  75%: 2.0723  95%: 3.8775\n"
     ]
    }
   ],
   "source": [
    "errors = np.array(np.array(true_EF_list) - np.array(derived_reported_EF_list))\n",
    "abs_errors = abs(errors)\n",
    "\n",
    "print(\"Mean absolute error (standard deviation):  {:.4f} ({:.4f}) %\".format(np.mean(abs_errors), np.std(abs_errors)))\n",
    "print(\"Median absolute error:  {:.4f} %\".format(np.median(abs_errors)))\n",
    "print(\"Bias +- 1.96 x std:  {:.4f} +- {:.4f}\".format(np.mean(errors), 1.96 * np.std(errors)))\n",
    "print(\"Percentile of mae 50%: {:6.4f}  75%: {:6.4f}  95%: {:6.4f}\".format(np.percentile(abs_errors, 50), np.percentile(abs_errors, 75),\n",
    "                                                                    np.percentile(abs_errors, 95)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-theology",
   "metadata": {},
   "source": [
    "### Cross Correlation between the Reported EF and EF computed from Reported ED/ES labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "steady-special",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross correlation with True EF: 0.978\n"
     ]
    }
   ],
   "source": [
    "corrcoef = np.corrcoef(np.array(true_EF_list), np.array(derived_reported_EF_list))\n",
    "print(\"Cross correlation with True EF: {:.3f}\".format(corrcoef[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-december",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
